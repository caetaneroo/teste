# input_manager.py

import logging
import pandas as pd
import awswrangler as wr
import re
from typing import Optional, Dict, Any, Union

logger = logging.getLogger(__name__)

# Suprimir logs do awswrangler.athena._utils
logging.getLogger("awswrangler.athena._utils").setLevel(logging.WARNING)

DEFAULT_ATHENA_DATABASE = "workspace_db"
DEFAULT_ATHENA_WORKGROUP = "analytics-workgroup-v3"

class InputManager:
    def __init__(
        self,
        athena_database: str = DEFAULT_ATHENA_DATABASE,
        athena_workgroup: str = DEFAULT_ATHENA_WORKGROUP,
        boto3_session: Optional[Any] = None
    ):
        self.athena_database = athena_database
        self.athena_workgroup = athena_workgroup
        self.boto3_session = boto3_session
        logger.info(
            f"InputManager inicializado | athena_database={self.athena_database} | athena_workgroup={self.athena_workgroup} | action=input_manager_init"
        )

    def _infer_filetype(self, path: str, filetype: Optional[str] = None) -> str:
        """
        Infere o tipo de arquivo a partir do sufixo, se filetype não for explicitamente informado.
        """
        if filetype:
            return filetype.lower()
        lowered = path.lower()
        if lowered.endswith(".parquet"):
            return "parquet"
        elif lowered.endswith(".csv"):
            return "csv"
        elif lowered.endswith(".json"):
            return "json"
        elif lowered.endswith(".xls") or lowered.endswith(".xlsx"):
            return "excel"
        else:
            raise ValueError("Não foi possível inferir o tipo do arquivo pelo sufixo. Informe o parâmetro 'filetype'.")

    def _log_dataframe_info(self, df: Optional[pd.DataFrame], source: str, error: Optional[str] = None):
        if df is not None and error is None:
            logger.info(
                f"LOAD-DATAFRAME | source={source} | success=True | n_rows={len(df)} | n_cols={len(df.columns)} | columns={list(df.columns)}"
            )
        else:
            logger.error(
                f"LOAD-DATAFRAME | source={source} | success=False | error={error}"
            )

    def from_athena(
        self,
        query: str,
        params: Optional[Dict[str, Any]] = None,
        ctas_database: Optional[str] = None,
        ctas_workgroup: Optional[str] = None,
        s3_output: Optional[str] = None
    ) -> Optional[pd.DataFrame]:
        """
        Executa uma query no Athena (modo CTAS) e retorna um DataFrame.
        """
        ctas_database = ctas_database or self.athena_database
        ctas_workgroup = ctas_workgroup or self.athena_workgroup
        try:
            df = wr.athena.read_sql_query(
                sql=query,
                database=ctas_database,
                workgroup=ctas_workgroup,
                ctas_approach=True,
                params=params,
                boto3_session=self.boto3_session,
                s3_output=s3_output
            )
            self._log_dataframe_info(df, source="Athena")
            return df
        except Exception as e:
            self._log_dataframe_info(None, source="Athena", error=str(e))
            return None

    def from_s3(
        self,
        s3_path: str,
        filetype: Optional[str] = None,
        **kwargs
    ) -> Optional[pd.DataFrame]:
        """
        Lê um arquivo do S3 e retorna um DataFrame.
        Suporta filetype: 'csv', 'parquet', 'json', 'excel'.
        """
        try:
            ftype = self._infer_filetype(s3_path, filetype)
            if ftype == "parquet":
                df = wr.s3.read_parquet(path=s3_path, boto3_session=self.boto3_session, **kwargs)
            elif ftype == "csv":
                df = wr.s3.read_csv(path=s3_path, boto3_session=self.boto3_session, **kwargs)
            elif ftype == "json":
                df = wr.s3.read_json(path=s3_path, boto3_session=self.boto3_session, **kwargs)
            elif ftype == "excel":
                df = wr.s3.read_excel(path=s3_path, boto3_session=self.boto3_session, **kwargs)
            else:
                raise ValueError(f"Tipo de arquivo não suportado para S3: {ftype}")
            self._log_dataframe_info(df, source=f"S3 ({ftype})")
            return df
        except Exception as e:
            self._log_dataframe_info(None, source=f"S3 ({filetype})", error=str(e))
            return None

    def from_local(
        self,
        filepath: str,
        filetype: Optional[str] = None,
        **kwargs
    ) -> Optional[pd.DataFrame]:
        """
        Lê um arquivo local e retorna um DataFrame.
        Suporta filetype: 'csv', 'parquet', 'json', 'excel'.
        """
        try:
            ftype = self._infer_filetype(filepath, filetype)
            if ftype == "parquet":
                df = pd.read_parquet(filepath, **kwargs)
            elif ftype == "csv":
                df = pd.read_csv(filepath, **kwargs)
            elif ftype == "json":
                df = pd.read_json(filepath, **kwargs)
            elif ftype == "excel":
                df = pd.read_excel(filepath, **kwargs)
            else:
                raise ValueError(f"Tipo de arquivo não suportado para local: {ftype}")
            self._log_dataframe_info(df, source=f"Local ({ftype})")
            return df
        except Exception as e:
            self._log_dataframe_info(None, source=f"Local ({filetype})", error=str(e))
            return None

    def from_txt_prompt(self, filepath: str, **kwargs) -> Optional[pd.DataFrame]:
        """
        Lê um arquivo .txt de prompt, valida a presença de {text} e retorna DataFrame com coluna 'prompt'.
        """
        try:
            with open(filepath, "r", encoding=kwargs.get("encoding", "utf-8")) as f:
                content = f.read()
            
            # Validação obrigatória: prompt deve conter {text}
            if "{text}" not in content:
                raise ValueError("O arquivo .txt de prompt deve conter obrigatoriamente o placeholder '{text}'.")
            
            # Checagem de placeholders extras
            other_placeholders = re.findall(r"\{([a-zA-Z0-9_]+)\}", content)
            if any(ph != "text" for ph in other_placeholders):
                logger.warning(
                    f"LOAD-TXT-PROMPT | filepath={filepath} | warning=Prompt contém placeholders além de '{{text}}': {set(other_placeholders) - {'text'}}. "
                    "Isso pode causar erro no ai_processor.py, pois ele só substitui {text}."
                )
            
            # Retorna DataFrame com uma coluna 'prompt'
            df = pd.DataFrame({"prompt": [content]})
            self._log_dataframe_info(df, source="Local (txt-prompt)")
            return df
        except Exception as e:
            self._log_dataframe_info(None, source="Local (txt-prompt)", error=str(e))
            return None

    def from_txt(self, filepath: str, **kwargs) -> Optional[str]:
        """
        Lê um arquivo .txt comum e retorna seu conteúdo como string.
        """
        try:
            with open(filepath, "r", encoding=kwargs.get("encoding", "utf-8")) as f:
                content = f.read()
            logger.info(
                f"LOAD-TXT | source=Local (txt) | success=True | n_chars={len(content)} | filepath={filepath}"
            )
            return content
        except Exception as e:
            logger.error(
                f"LOAD-TXT | source=Local (txt) | success=False | error={str(e)} | filepath={filepath}"
            )
            return None
