# core/stats_manager.py
import time
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List

@dataclass
class Stats:
    """Classe única para qualquer tipo de estatística - batch ou global"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_tokens_input: int = 0
    total_tokens_output: int = 0
    total_tokens_cached: int = 0  # Tokens cached para economia
    total_cost: float = 0.0
    rate_limit_waits: int = 0
    processing_time: float = 0.0
    start_time: float = field(default_factory=time.time)
    
    # MÉTRICAS DE PERFORMANCE DETALHADAS
    total_api_response_time: float = 0.0  # Tempo total de resposta da API
    min_response_time: float = float('inf')  # Menor tempo de resposta
    max_response_time: float = 0.0  # Maior tempo de resposta
    total_wait_time: float = 0.0  # Tempo total aguardando rate limits
    retry_attempts: int = 0  # Total de tentativas de retry
    concurrent_peak: int = 0  # Pico de requisições simultâneas (CORRIGIDO)
    errors_by_type: Dict[str, int] = field(default_factory=dict)  # Erros por tipo
    
    # ✅ NOVAS: Métricas de rate limiting coordenado
    api_rate_limits_detected: int = 0  # Rate limits detectados pela API
    global_rate_limit_activations: int = 0  # Vezes que rate limit global foi ativado
    coordinated_wait_time: float = 0.0  # Tempo total de espera coordenada
    
    @property
    def total_tokens(self) -> int:
        """Total de tokens (input + output + cached)"""
        return self.total_tokens_input + self.total_tokens_output + self.total_tokens_cached
    
    @property
    def success_rate(self) -> float:
        """Taxa de sucesso em percentual"""
        return (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0
    
    @property
    def avg_rate(self) -> float:
        """Taxa média de requisições por segundo"""
        return (self.successful_requests / self.processing_time) if self.processing_time > 0 else 0
    
    @property
    def avg_response_time(self) -> float:
        """Tempo médio de resposta da API"""
        return (self.total_api_response_time / self.successful_requests) if self.successful_requests > 0 else 0
    
    @property
    def efficiency_rate(self) -> float:
        """% do tempo gasto processando vs aguardando rate limits"""
        total_time = self.processing_time
        if total_time <= 0:
            return 0
        processing_time = total_time - self.total_wait_time
        return (processing_time / total_time * 100) if total_time > 0 else 0
    
    @property
    def retry_rate(self) -> float:
        """Taxa de retry por requisição"""
        return (self.retry_attempts / self.total_requests) if self.total_requests > 0 else 0
    
    @property
    def cost_per_token(self) -> float:
        """Custo médio por token"""
        return (self.total_cost / self.total_tokens) if self.total_tokens > 0 else 0
    
    @property
    def cache_hit_rate(self) -> float:
        """Taxa de cache hit em percentual"""
        total_input_and_cached = self.total_tokens_input + self.total_tokens_cached
        return (self.total_tokens_cached / total_input_and_cached * 100) if total_input_and_cached > 0 else 0
    
    @property
    def cost_savings_from_cache(self) -> float:
        """Economia estimada com tokens cached (50% desconto típico)"""
        # Estimativa conservadora: cached tokens custam 50% menos
        return self.total_tokens_cached * 0.5 * 0.0015 / 1000
    
    @property
    def coordination_efficiency(self) -> float:
        """Eficiência da coordenação vs rate limits individuais"""
        if self.api_rate_limits_detected == 0:
            return 100.0
        return (1 - (self.global_rate_limit_activations / self.api_rate_limits_detected)) * 100

class StatsManager:
    """
    Gerenciador único que serve batch e global - com rate limiting coordenado
    
    Características:
    - Tracking automático de diferenças para stats de batch
    - Métricas completas incluindo cached tokens e coordenação
    - Formatação consistente para qualquer tipo de stats
    - Comparação entre batches sem repetição
    - Pico concorrente CORRIGIDO para mostrar valor real
    """
    
    def __init__(self):
        self.global_stats = Stats()
        self._batch_snapshots = {}
        self._current_concurrent = 0  # Tracking de concorrência atual (CORRIGIDO)
    
    def start_batch(self, batch_id: str) -> None:
        """Inicia tracking de um batch - CORRIGIDO: resetar pico concorrente"""
        self._batch_snapshots[batch_id] = {
            'start_time': time.time(),
            'batch_concurrent_peak': 0,  # ✅ CORREÇÃO: Pico específico do batch
            'start_stats': Stats(
                total_requests=self.global_stats.total_requests,
                successful_requests=self.global_stats.successful_requests,
                failed_requests=self.global_stats.failed_requests,
                total_tokens_input=self.global_stats.total_tokens_input,
                total_tokens_output=self.global_stats.total_tokens_output,
                total_tokens_cached=self.global_stats.total_tokens_cached,
                total_cost=self.global_stats.total_cost,
                rate_limit_waits=self.global_stats.rate_limit_waits,
                total_api_response_time=self.global_stats.total_api_response_time,
                total_wait_time=self.global_stats.total_wait_time,
                retry_attempts=self.global_stats.retry_attempts,
                concurrent_peak=0,  # ✅ CORREÇÃO: Resetar para o batch
                errors_by_type=self.global_stats.errors_by_type.copy(),
                
                # ✅ NOVAS métricas de coordenação
                api_rate_limits_detected=self.global_stats.api_rate_limits_detected,
                global_rate_limit_activations=self.global_stats.global_rate_limit_activations,
                coordinated_wait_time=self.global_stats.coordinated_wait_time
            )
        }
    
    def end_batch(self, batch_id: str) -> Stats:
        """Finaliza batch e retorna stats apenas desse batch - CORRIGIDO"""
        if batch_id not in self._batch_snapshots:
            raise ValueError(f"Batch {batch_id} não foi iniciado")
        
        snapshot = self._batch_snapshots[batch_id]
        start_stats = snapshot['start_stats']
        end_time = time.time()
        
        # Calcular diferença = stats apenas deste batch
        batch_stats = Stats(
            total_requests=self.global_stats.total_requests - start_stats.total_requests,
            successful_requests=self.global_stats.successful_requests - start_stats.successful_requests,
            failed_requests=self.global_stats.failed_requests - start_stats.failed_requests,
            total_tokens_input=self.global_stats.total_tokens_input - start_stats.total_tokens_input,
            total_tokens_output=self.global_stats.total_tokens_output - start_stats.total_tokens_output,
            total_tokens_cached=self.global_stats.total_tokens_cached - start_stats.total_tokens_cached,
            total_cost=self.global_stats.total_cost - start_stats.total_cost,
            rate_limit_waits=self.global_stats.rate_limit_waits - start_stats.rate_limit_waits,
            processing_time=end_time - snapshot['start_time'],
            start_time=snapshot['start_time'],
            
            # Métricas de performance
            total_api_response_time=self.global_stats.total_api_response_time - start_stats.total_api_response_time,
            min_response_time=self.global_stats.min_response_time if self.global_stats.min_response_time != float('inf') else 0,
            max_response_time=self.global_stats.max_response_time,
            total_wait_time=self.global_stats.total_wait_time - start_stats.total_wait_time,
            retry_attempts=self.global_stats.retry_attempts - start_stats.retry_attempts,
            
            # ✅ CORREÇÃO: Usar pico específico do batch, não global
            concurrent_peak=snapshot.get('batch_concurrent_peak', 0),
            
            # ✅ NOVAS métricas de coordenação
            api_rate_limits_detected=self.global_stats.api_rate_limits_detected - start_stats.api_rate_limits_detected,
            global_rate_limit_activations=self.global_stats.global_rate_limit_activations - start_stats.global_rate_limit_activations,
            coordinated_wait_time=self.global_stats.coordinated_wait_time - start_stats.coordinated_wait_time,
            
            # Erros por tipo (diferença)
            errors_by_type={
                error_type: self.global_stats.errors_by_type.get(error_type, 0) - start_stats.errors_by_type.get(error_type, 0)
                for error_type in set(list(self.global_stats.errors_by_type.keys()) + list(start_stats.errors_by_type.keys()))
                if (self.global_stats.errors_by_type.get(error_type, 0) - start_stats.errors_by_type.get(error_type, 0)) > 0
            }
        )
        
        # Limpar snapshot
        del self._batch_snapshots[batch_id]
        
        return batch_stats
    
    def record_request(self, success: bool, tokens_input: int = 0, 
                      tokens_output: int = 0, tokens_cached: int = 0,
                      cost: float = 0.0, api_response_time: float = 0.0, 
                      error_type: str = None, retry_count: int = 0,
                      # ✅ NOVOS parâmetros para rate limiting coordenado
                      api_rate_limit_detected: bool = False,
                      coordinated_wait_time: float = 0.0) -> None:
        """Registra uma requisição com métricas de rate limiting coordenado"""
        
        self.global_stats.total_requests += 1
        
        if success:
            self.global_stats.successful_requests += 1
            
            # Métricas de response time
            if api_response_time > 0:
                self.global_stats.total_api_response_time += api_response_time
                self.global_stats.min_response_time = min(self.global_stats.min_response_time, api_response_time)
                self.global_stats.max_response_time = max(self.global_stats.max_response_time, api_response_time)
            
        else:
            self.global_stats.failed_requests += 1
            
            # Contar erros por tipo
            if error_type:
                if error_type not in self.global_stats.errors_by_type:
                    self.global_stats.errors_by_type[error_type] = 0
                self.global_stats.errors_by_type[error_type] += 1
        
        # Métricas gerais incluindo cached tokens
        self.global_stats.total_tokens_input += tokens_input
        self.global_stats.total_tokens_output += tokens_output
        self.global_stats.total_tokens_cached += tokens_cached
        self.global_stats.total_cost += cost
        self.global_stats.retry_attempts += retry_count
        
        # ✅ NOVAS métricas de coordenação
        if api_rate_limit_detected:
            self.global_stats.api_rate_limits_detected += 1
        
        if coordinated_wait_time > 0:
            self.global_stats.coordinated_wait_time += coordinated_wait_time
    
    def record_rate_limit(self) -> None:
        """Registra uma espera por rate limit (compatibilidade)"""
        self.global_stats.rate_limit_waits += 1
    
    def record_rate_limit_wait(self, wait_time: float) -> None:
        """Registra espera por rate limit com tempo"""
        self.global_stats.rate_limit_waits += 1
        self.global_stats.total_wait_time += wait_time
    
    def record_global_rate_limit_activation(self, wait_time: float, requests_affected: int = 0) -> None:
        """Registra ativação de rate limit global coordenado"""
        self.global_stats.global_rate_limit_activations += 1
        self.global_stats.coordinated_wait_time += wait_time
        
        import logging
        logger = logging.getLogger(__name__)
        logger.debug(
            "Rate limit global registrado nas estatísticas",
            extra={
                'wait_time': wait_time,
                'requests_affected': requests_affected,
                'total_activations': self.global_stats.global_rate_limit_activations,
                'action': 'global_rate_limit_stats'
            }
        )
    
    def record_concurrent_start(self) -> None:
        """Registra início de requisição concorrente - CORRIGIDO"""
        self._current_concurrent += 1
        
        # ✅ CORREÇÃO: Atualizar pico global
        self.global_stats.concurrent_peak = max(self.global_stats.concurrent_peak, self._current_concurrent)
        
        # ✅ CORREÇÃO: Atualizar pico apenas dos batches ativos
        for batch_id, snapshot in self._batch_snapshots.items():
            snapshot['batch_concurrent_peak'] = max(
                snapshot.get('batch_concurrent_peak', 0), 
                self._current_concurrent
            )
    
    def record_concurrent_end(self) -> None:
        """Registra fim de requisição concorrente"""
        self._current_concurrent = max(0, self._current_concurrent - 1)
    
    def get_global_stats(self) -> Stats:
        """Retorna stats globais atualizadas"""
        self.global_stats.processing_time = time.time() - self.global_stats.start_time
        return self.global_stats
    
    def format_stats(self, stats: Stats, title: str = "Stats") -> str:
        """Formata qualquer stats de forma consistente com todas as métricas"""
        
        # Preparar erros por tipo
        errors_summary = ""
        if stats.errors_by_type:
            error_list = [f"{error_type}: {count}" for error_type, count in stats.errors_by_type.items()]
            errors_summary = f"\n   🚨 Erros: {', '.join(error_list)}"
        
        # Formatação básica com tokens detalhados
        basic_stats = f"""📊 {title.upper()}:
   ✅ Sucessos: {stats.successful_requests}
   ❌ Falhas: {stats.failed_requests}
   🔢 Tokens total: {stats.total_tokens:,}
   📥 Tokens input: {stats.total_tokens_input:,}
   📤 Tokens output: {stats.total_tokens_output:,}
   💾 Tokens cached: {stats.total_tokens_cached:,}
   💰 Custo: ${stats.total_cost:.4f}
   ⏱️ Tempo total: {stats.processing_time:.2f}s
   📈 Taxa: {stats.avg_rate:.2f} req/s
   📊 Sucesso: {stats.success_rate:.1f}%"""
        
        # Adicionar métricas de cache se houver dados
        cache_stats = ""
        if stats.total_tokens_cached > 0:
            cache_stats = f"""
   
   💾 CACHE PERFORMANCE:
   🎯 Cache hit rate: {stats.cache_hit_rate:.1f}%
   💵 Economia estimada: ${stats.cost_savings_from_cache:.4f}"""
        
        # Adicionar métricas de performance se houver dados
        performance_stats = ""
        if stats.successful_requests > 0 and stats.avg_response_time > 0:
            performance_stats = f"""
   
   🚀 PERFORMANCE:
   ⚡ Response time médio: {stats.avg_response_time:.3f}s
   ⚡ Response time min/max: {stats.min_response_time:.3f}s / {stats.max_response_time:.3f}s
   🔄 Taxa de retry: {stats.retry_rate:.2f} retries/req
   ⏳ Eficiência: {stats.efficiency_rate:.1f}% (tempo processando vs aguardando)
   🔗 Pico concorrente: {stats.concurrent_peak} requisições
   💵 Custo por token: ${stats.cost_per_token:.6f}"""
        
        # ✅ ADICIONAR seção de coordenação se houver dados
        coordination_stats = ""
        if stats.api_rate_limits_detected > 0:
            coordination_stats = f"""
   
   🤝 COORDENAÇÃO DE RATE LIMITS:
   🚨 Rate limits detectados: {stats.api_rate_limits_detected}
   🌐 Ativações globais: {stats.global_rate_limit_activations}
   ⏱️ Tempo coordenado: {stats.coordinated_wait_time:.1f}s
   📈 Eficiência coordenação: {stats.coordination_efficiency:.1f}%"""
        
        # Adicionar rate limits se houver
        rate_limit_stats = ""
        if stats.rate_limit_waits > 0:
            rate_limit_stats = f"\n   ⏳ Rate limits: {stats.rate_limit_waits} ({stats.total_wait_time:.1f}s total)"
        
        return basic_stats + cache_stats + performance_stats + coordination_stats + rate_limit_stats + errors_summary
    
    def reset_global(self) -> None:
        """Reset stats globais"""
        self.global_stats = Stats()
        self._current_concurrent = 0
    
    def compare_batches(self, *batch_results) -> str:
        """Compara múltiplos batches sem repetição"""
        
        output = ["📊 COMPARAÇÃO DE BATCHES:", "=" * 80]
        
        for i, result in enumerate(batch_results, 1):
            batch_stats = result['batch_stats']
            batch_id = result.get('batch_id', f'batch_{i}')
            
            output.append(f"\n🔍 Batch {i} ({batch_id}):")
            
            # Usar o formatador único
            batch_formatted = self.format_stats(
                batch_stats, 
                title="", 
            ).replace("📊 :", "").strip()
            
            # Indentar as linhas
            for line in batch_formatted.split('\n'):
                if line.strip():
                    output.append(f"   {line.strip()}")
        
        return "\n".join(output)
    
    def summary_report(self, batch_results: List[Dict], global_stats: Stats) -> str:
        """Relatório completo sem repetição"""
        
        output = ["🎯 RELATÓRIO COMPLETO", "=" * 80]
        
        # Batches individuais
        for i, result in enumerate(batch_results, 1):
            batch_stats = result['batch_stats']
            batch_id = result.get('batch_id', f'batch_{i}')
            
            formatted = self.format_stats(
                batch_stats, 
                title=f"Batch {i} ({batch_id})"
            )
            output.append(f"\n{formatted}")
        
        # Global
        formatted_global = self.format_stats(
            global_stats, 
            title="TOTAL GERAL"
        )
        output.append(f"\n{formatted_global}")
        
        return "\n".join(output)
    
    def get_efficiency_metrics(self, stats: Stats) -> Dict[str, Any]:
        """Retorna métricas de eficiência calculadas"""
        return {
            'throughput_per_minute': stats.successful_requests / (stats.processing_time / 60) if stats.processing_time > 0 else 0,
            'cost_efficiency': stats.total_cost / stats.successful_requests if stats.successful_requests > 0 else 0,
            'time_efficiency': stats.efficiency_rate,
            'cache_efficiency': stats.cache_hit_rate,
            'coordination_efficiency': stats.coordination_efficiency,
            'error_rate': (stats.failed_requests / stats.total_requests * 100) if stats.total_requests > 0 else 0,
            'avg_tokens_per_request': stats.total_tokens / stats.total_requests if stats.total_requests > 0 else 0
        }
    
    def get_cost_breakdown(self, stats: Stats) -> Dict[str, Any]:
        """Retorna breakdown detalhado de custos"""
        return {
            'total_cost': stats.total_cost,
            'cost_per_request': stats.total_cost / stats.successful_requests if stats.successful_requests > 0 else 0,
            'cost_per_token': stats.cost_per_token,
            'estimated_savings_from_cache': stats.cost_savings_from_cache,
            'cost_breakdown': {
                'input_tokens_cost': stats.total_tokens_input * stats.cost_per_token if stats.cost_per_token > 0 else 0,
                'output_tokens_cost': stats.total_tokens_output * stats.cost_per_token if stats.cost_per_token > 0 else 0,
                'cached_tokens_savings': stats.cost_savings_from_cache
            }
        }
    
    def export_stats_json(self, stats: Stats) -> Dict[str, Any]:
        """Exporta stats em formato JSON para análise externa"""
        return {
            'basic_metrics': {
                'total_requests': stats.total_requests,
                'successful_requests': stats.successful_requests,
                'failed_requests': stats.failed_requests,
                'success_rate': stats.success_rate
            },
            'token_metrics': {
                'total_tokens': stats.total_tokens,
                'input_tokens': stats.total_tokens_input,
                'output_tokens': stats.total_tokens_output,
                'cached_tokens': stats.total_tokens_cached,
                'cache_hit_rate': stats.cache_hit_rate
            },
            'performance_metrics': {
                'processing_time': stats.processing_time,
                'avg_response_time': stats.avg_response_time,
                'min_response_time': stats.min_response_time,
                'max_response_time': stats.max_response_time,
                'avg_rate': stats.avg_rate,
                'efficiency_rate': stats.efficiency_rate,
                'concurrent_peak': stats.concurrent_peak
            },
            'cost_metrics': {
                'total_cost': stats.total_cost,
                'cost_per_token': stats.cost_per_token,
                'cost_savings_from_cache': stats.cost_savings_from_cache
            },
            'reliability_metrics': {
                'rate_limit_waits': stats.rate_limit_waits,
                'total_wait_time': stats.total_wait_time,
                'retry_attempts': stats.retry_attempts,
                'retry_rate': stats.retry_rate,
                'errors_by_type': stats.errors_by_type
            },
            'coordination_metrics': {
                'api_rate_limits_detected': stats.api_rate_limits_detected,
                'global_rate_limit_activations': stats.global_rate_limit_activations,
                'coordinated_wait_time': stats.coordinated_wait_time,
                'coordination_efficiency': stats.coordination_efficiency
            }
        }
