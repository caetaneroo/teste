# core/stats_manager.py
import time
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List

@dataclass
class Stats:
    """Classe √∫nica para qualquer tipo de estat√≠stica - batch ou global"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_tokens_input: int = 0
    total_tokens_output: int = 0
    total_tokens_cached: int = 0  # Tokens cached para economia
    total_cost: float = 0.0
    rate_limit_waits: int = 0
    processing_time: float = 0.0
    start_time: float = field(default_factory=time.time)
    
    # M√âTRICAS DE PERFORMANCE DETALHADAS
    total_api_response_time: float = 0.0  # Tempo total de resposta da API
    min_response_time: float = float('inf')  # Menor tempo de resposta
    max_response_time: float = 0.0  # Maior tempo de resposta
    total_wait_time: float = 0.0  # Tempo total aguardando rate limits
    retry_attempts: int = 0  # Total de tentativas de retry
    concurrent_peak: int = 0  # Pico de requisi√ß√µes simult√¢neas
    errors_by_type: Dict[str, int] = field(default_factory=dict)  # Erros por tipo
    
    @property
    def total_tokens(self) -> int:
        """Total de tokens (input + output + cached)"""
        return self.total_tokens_input + self.total_tokens_output + self.total_tokens_cached
    
    @property
    def success_rate(self) -> float:
        """Taxa de sucesso em percentual"""
        return (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0
    
    @property
    def avg_rate(self) -> float:
        """Taxa m√©dia de requisi√ß√µes por segundo"""
        return (self.successful_requests / self.processing_time) if self.processing_time > 0 else 0
    
    @property
    def avg_response_time(self) -> float:
        """Tempo m√©dio de resposta da API"""
        return (self.total_api_response_time / self.successful_requests) if self.successful_requests > 0 else 0
    
    @property
    def efficiency_rate(self) -> float:
        """% do tempo gasto processando vs aguardando rate limits"""
        total_time = self.processing_time
        if total_time <= 0:
            return 0
        processing_time = total_time - self.total_wait_time
        return (processing_time / total_time * 100) if total_time > 0 else 0
    
    @property
    def retry_rate(self) -> float:
        """Taxa de retry por requisi√ß√£o"""
        return (self.retry_attempts / self.total_requests) if self.total_requests > 0 else 0
    
    @property
    def cost_per_token(self) -> float:
        """Custo m√©dio por token"""
        return (self.total_cost / self.total_tokens) if self.total_tokens > 0 else 0
    
    @property
    def cache_hit_rate(self) -> float:
        """Taxa de cache hit em percentual"""
        total_input_and_cached = self.total_tokens_input + self.total_tokens_cached
        return (self.total_tokens_cached / total_input_and_cached * 100) if total_input_and_cached > 0 else 0
    
    @property
    def cost_savings_from_cache(self) -> float:
        """Economia estimada com tokens cached (50% desconto t√≠pico)"""
        # Estimativa conservadora: cached tokens custam 50% menos
        return self.total_tokens_cached * 0.5 * 0.0015 / 1000

class StatsManager:
    """
    Gerenciador √∫nico que serve batch e global - elimina repeti√ß√£o de c√≥digo
    
    CORRE√á√ÉO: Tracking de concorr√™ncia corrigido para mostrar pico real por batch
    """
    
    def __init__(self):
        self.global_stats = Stats()
        self._batch_snapshots = {}
        self._current_concurrent = 0  # Tracking de concorr√™ncia atual
    
    def start_batch(self, batch_id: str) -> None:
        """Inicia tracking de um batch - CORRIGIDO: resetar pico concorrente"""
        self._batch_snapshots[batch_id] = {
            'start_time': time.time(),
            'batch_concurrent_peak': 0,  # ‚úÖ CORRE√á√ÉO: Pico espec√≠fico do batch
            'start_stats': Stats(
                total_requests=self.global_stats.total_requests,
                successful_requests=self.global_stats.successful_requests,
                failed_requests=self.global_stats.failed_requests,
                total_tokens_input=self.global_stats.total_tokens_input,
                total_tokens_output=self.global_stats.total_tokens_output,
                total_tokens_cached=self.global_stats.total_tokens_cached,
                total_cost=self.global_stats.total_cost,
                rate_limit_waits=self.global_stats.rate_limit_waits,
                total_api_response_time=self.global_stats.total_api_response_time,
                total_wait_time=self.global_stats.total_wait_time,
                retry_attempts=self.global_stats.retry_attempts,
                concurrent_peak=0,  # ‚úÖ CORRE√á√ÉO: Resetar para o batch
                errors_by_type=self.global_stats.errors_by_type.copy()
            )
        }
    
    def end_batch(self, batch_id: str) -> Stats:
        """Finaliza batch e retorna stats apenas desse batch - CORRIGIDO"""
        if batch_id not in self._batch_snapshots:
            raise ValueError(f"Batch {batch_id} n√£o foi iniciado")
        
        snapshot = self._batch_snapshots[batch_id]
        start_stats = snapshot['start_stats']
        end_time = time.time()
        
        # Calcular diferen√ßa = stats apenas deste batch
        batch_stats = Stats(
            total_requests=self.global_stats.total_requests - start_stats.total_requests,
            successful_requests=self.global_stats.successful_requests - start_stats.successful_requests,
            failed_requests=self.global_stats.failed_requests - start_stats.failed_requests,
            total_tokens_input=self.global_stats.total_tokens_input - start_stats.total_tokens_input,
            total_tokens_output=self.global_stats.total_tokens_output - start_stats.total_tokens_output,
            total_tokens_cached=self.global_stats.total_tokens_cached - start_stats.total_tokens_cached,
            total_cost=self.global_stats.total_cost - start_stats.total_cost,
            rate_limit_waits=self.global_stats.rate_limit_waits - start_stats.rate_limit_waits,
            processing_time=end_time - snapshot['start_time'],
            start_time=snapshot['start_time'],
            
            # M√©tricas de performance
            total_api_response_time=self.global_stats.total_api_response_time - start_stats.total_api_response_time,
            min_response_time=self.global_stats.min_response_time if self.global_stats.min_response_time != float('inf') else 0,
            max_response_time=self.global_stats.max_response_time,
            total_wait_time=self.global_stats.total_wait_time - start_stats.total_wait_time,
            retry_attempts=self.global_stats.retry_attempts - start_stats.retry_attempts,
            
            # ‚úÖ CORRE√á√ÉO: Usar pico espec√≠fico do batch, n√£o global
            concurrent_peak=snapshot.get('batch_concurrent_peak', 0),
            
            # Erros por tipo (diferen√ßa)
            errors_by_type={
                error_type: self.global_stats.errors_by_type.get(error_type, 0) - start_stats.errors_by_type.get(error_type, 0)
                for error_type in set(list(self.global_stats.errors_by_type.keys()) + list(start_stats.errors_by_type.keys()))
                if (self.global_stats.errors_by_type.get(error_type, 0) - start_stats.errors_by_type.get(error_type, 0)) > 0
            }
        )
        
        # Limpar snapshot
        del self._batch_snapshots[batch_id]
        
        return batch_stats
    
    def record_request(self, success: bool, tokens_input: int = 0, 
                      tokens_output: int = 0, tokens_cached: int = 0,
                      cost: float = 0.0, api_response_time: float = 0.0, 
                      error_type: str = None, retry_count: int = 0) -> None:
        """Registra uma requisi√ß√£o com m√©tricas detalhadas incluindo cached tokens"""
        
        self.global_stats.total_requests += 1
        
        if success:
            self.global_stats.successful_requests += 1
            
            # M√©tricas de response time
            if api_response_time > 0:
                self.global_stats.total_api_response_time += api_response_time
                self.global_stats.min_response_time = min(self.global_stats.min_response_time, api_response_time)
                self.global_stats.max_response_time = max(self.global_stats.max_response_time, api_response_time)
            
        else:
            self.global_stats.failed_requests += 1
            
            # Contar erros por tipo
            if error_type:
                if error_type not in self.global_stats.errors_by_type:
                    self.global_stats.errors_by_type[error_type] = 0
                self.global_stats.errors_by_type[error_type] += 1
        
        # M√©tricas gerais incluindo cached tokens
        self.global_stats.total_tokens_input += tokens_input
        self.global_stats.total_tokens_output += tokens_output
        self.global_stats.total_tokens_cached += tokens_cached
        self.global_stats.total_cost += cost
        self.global_stats.retry_attempts += retry_count
    
    def record_rate_limit(self) -> None:
        """Registra uma espera por rate limit (compatibilidade)"""
        self.global_stats.rate_limit_waits += 1
    
    def record_rate_limit_wait(self, wait_time: float) -> None:
        """Registra espera por rate limit com tempo"""
        self.global_stats.rate_limit_waits += 1
        self.global_stats.total_wait_time += wait_time
    
    def record_concurrent_start(self) -> None:
        """Registra in√≠cio de requisi√ß√£o concorrente - CORRIGIDO"""
        self._current_concurrent += 1
        
        # ‚úÖ CORRE√á√ÉO: Atualizar pico global
        self.global_stats.concurrent_peak = max(self.global_stats.concurrent_peak, self._current_concurrent)
        
        # ‚úÖ CORRE√á√ÉO: Atualizar pico apenas dos batches ativos
        for batch_id, snapshot in self._batch_snapshots.items():
            snapshot['batch_concurrent_peak'] = max(
                snapshot.get('batch_concurrent_peak', 0), 
                self._current_concurrent
            )
    
    def record_concurrent_end(self) -> None:
        """Registra fim de requisi√ß√£o concorrente"""
        self._current_concurrent = max(0, self._current_concurrent - 1)
    
    def get_global_stats(self) -> Stats:
        """Retorna stats globais atualizadas"""
        self.global_stats.processing_time = time.time() - self.global_stats.start_time
        return self.global_stats
    
    def format_stats(self, stats: Stats, title: str = "Stats") -> str:
        """Formata qualquer stats de forma consistente com todas as m√©tricas"""
        
        # Preparar erros por tipo
        errors_summary = ""
        if stats.errors_by_type:
            error_list = [f"{error_type}: {count}" for error_type, count in stats.errors_by_type.items()]
            errors_summary = f"\n   üö® Erros: {', '.join(error_list)}"
        
        # Formata√ß√£o b√°sica com tokens detalhados
        basic_stats = f"""üìä {title.upper()}:
   ‚úÖ Sucessos: {stats.successful_requests}
   ‚ùå Falhas: {stats.failed_requests}
   üî¢ Tokens total: {stats.total_tokens:,}
   üì• Tokens input: {stats.total_tokens_input:,}
   üì§ Tokens output: {stats.total_tokens_output:,}
   üíæ Tokens cached: {stats.total_tokens_cached:,}
   üí∞ Custo: ${stats.total_cost:.4f}
   ‚è±Ô∏è Tempo total: {stats.processing_time:.2f}s
   üìà Taxa: {stats.avg_rate:.2f} req/s
   üìä Sucesso: {stats.success_rate:.1f}%"""
        
        # Adicionar m√©tricas de cache se houver dados
        cache_stats = ""
        if stats.total_tokens_cached > 0:
            cache_stats = f"""
   
   üíæ CACHE PERFORMANCE:
   üéØ Cache hit rate: {stats.cache_hit_rate:.1f}%
   üíµ Economia estimada: ${stats.cost_savings_from_cache:.4f}"""
        
        # Adicionar m√©tricas de performance se houver dados
        performance_stats = ""
        if stats.successful_requests > 0 and stats.avg_response_time > 0:
            performance_stats = f"""
   
   üöÄ PERFORMANCE:
   ‚ö° Response time m√©dio: {stats.avg_response_time:.3f}s
   ‚ö° Response time min/max: {stats.min_response_time:.3f}s / {stats.max_response_time:.3f}s
   üîÑ Taxa de retry: {stats.retry_rate:.2f} retries/req
   ‚è≥ Efici√™ncia: {stats.efficiency_rate:.1f}% (tempo processando vs aguardando)
   üîó Pico concorrente: {stats.concurrent_peak} requisi√ß√µes
   üíµ Custo por token: ${stats.cost_per_token:.6f}"""
        
        # Adicionar rate limits se houver
        rate_limit_stats = ""
        if stats.rate_limit_waits > 0:
            rate_limit_stats = f"\n   ‚è≥ Rate limits: {stats.rate_limit_waits} ({stats.total_wait_time:.1f}s total)"
        
        return basic_stats + cache_stats + performance_stats + rate_limit_stats + errors_summary
    
    def reset_global(self) -> None:
        """Reset stats globais"""
        self.global_stats = Stats()
        self._current_concurrent = 0
    
    def compare_batches(self, *batch_results) -> str:
        """Compara m√∫ltiplos batches sem repeti√ß√£o"""
        
        output = ["üìä COMPARA√á√ÉO DE BATCHES:", "=" * 80]
        
        for i, result in enumerate(batch_results, 1):
            batch_stats = result['batch_stats']
            batch_id = result.get('batch_id', f'batch_{i}')
            
            output.append(f"\nüîç Batch {i} ({batch_id}):")
            
            # Usar o formatador √∫nico
            batch_formatted = self.format_stats(
                batch_stats, 
                title="", 
            ).replace("üìä :", "").strip()
            
            # Indentar as linhas
            for line in batch_formatted.split('\n'):
                if line.strip():
                    output.append(f"   {line.strip()}")
        
        return "\n".join(output)
    
    def summary_report(self, batch_results: List[Dict], global_stats: Stats) -> str:
        """Relat√≥rio completo sem repeti√ß√£o"""
        
        output = ["üéØ RELAT√ìRIO COMPLETO", "=" * 80]
        
        # Batches individuais
        for i, result in enumerate(batch_results, 1):
            batch_stats = result['batch_stats']
            batch_id = result.get('batch_id', f'batch_{i}')
            
            formatted = self.format_stats(
                batch_stats, 
                title=f"Batch {i} ({batch_id})"
            )
            output.append(f"\n{formatted}")
        
        # Global
        formatted_global = self.format_stats(
            global_stats, 
            title="TOTAL GERAL"
        )
        output.append(f"\n{formatted_global}")
        
        return "\n".join(output)
    
    def get_efficiency_metrics(self, stats: Stats) -> Dict[str, Any]:
        """Retorna m√©tricas de efici√™ncia calculadas"""
        return {
            'throughput_per_minute': stats.successful_requests / (stats.processing_time / 60) if stats.processing_time > 0 else 0,
            'cost_efficiency': stats.total_cost / stats.successful_requests if stats.successful_requests > 0 else 0,
            'time_efficiency': stats.efficiency_rate,
            'cache_efficiency': stats.cache_hit_rate,
            'error_rate': (stats.failed_requests / stats.total_requests * 100) if stats.total_requests > 0 else 0,
            'avg_tokens_per_request': stats.total_tokens / stats.total_requests if stats.total_requests > 0 else 0
        }
    
    def get_cost_breakdown(self, stats: Stats) -> Dict[str, Any]:
        """Retorna breakdown detalhado de custos"""
        return {
            'total_cost': stats.total_cost,
            'cost_per_request': stats.total_cost / stats.successful_requests if stats.successful_requests > 0 else 0,
            'cost_per_token': stats.cost_per_token,
            'estimated_savings_from_cache': stats.cost_savings_from_cache,
            'cost_breakdown': {
                'input_tokens_cost': stats.total_tokens_input * stats.cost_per_token if stats.cost_per_token > 0 else 0,
                'output_tokens_cost': stats.total_tokens_output * stats.cost_per_token if stats.cost_per_token > 0 else 0,
                'cached_tokens_savings': stats.cost_savings_from_cache
            }
        }
    
    def export_stats_json(self, stats: Stats) -> Dict[str, Any]:
        """Exporta stats em formato JSON para an√°lise externa"""
        return {
            'basic_metrics': {
                'total_requests': stats.total_requests,
                'successful_requests': stats.successful_requests,
                'failed_requests': stats.failed_requests,
                'success_rate': stats.success_rate
            },
            'token_metrics': {
                'total_tokens': stats.total_tokens,
                'input_tokens': stats.total_tokens_input,
                'output_tokens': stats.total_tokens_output,
                'cached_tokens': stats.total_tokens_cached,
                'cache_hit_rate': stats.cache_hit_rate
            },
            'performance_metrics': {
                'processing_time': stats.processing_time,
                'avg_response_time': stats.avg_response_time,
                'min_response_time': stats.min_response_time,
                'max_response_time': stats.max_response_time,
                'avg_rate': stats.avg_rate,
                'efficiency_rate': stats.efficiency_rate,
                'concurrent_peak': stats.concurrent_peak
            },
            'cost_metrics': {
                'total_cost': stats.total_cost,
                'cost_per_token': stats.cost_per_token,
                'cost_savings_from_cache': stats.cost_savings_from_cache
            },
            'reliability_metrics': {
                'rate_limit_waits': stats.rate_limit_waits,
                'total_wait_time': stats.total_wait_time,
                'retry_attempts': stats.retry_attempts,
                'retry_rate': stats.retry_rate,
                'errors_by_type': stats.errors_by_type
            }
        }
