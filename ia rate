# core/rate_limiter.py
import asyncio
import time
import logging
from typing import Dict, Any, Optional
from collections import deque
from dataclasses import dataclass

# Logger específico do módulo
logger = logging.getLogger(__name__)

@dataclass
class TokenUsageRecord:
    """Registro de uso de tokens para calibração adaptativa"""
    estimated_tokens: int
    actual_tokens: int
    timestamp: float
    accuracy_ratio: float

class AdaptiveRateLimiter:
    """
    Rate limiter com calibração adaptativa e controle global coordenado
    
    Características:
    - Calibra estimativas com base em dados históricos reais
    - Auto-ajuste estatístico para otimizar precisão
    - Rate limiting global coordenado (uma warning por batch)
    - Prevenção proativa de rate limits
    - Máximo aproveitamento da quota disponível
    """
    
    def __init__(self, max_tokens_per_minute: int = 180000, calibration_enabled: bool = True):
        self.max_tpm = max_tokens_per_minute
        self.tokens_used_this_minute = 0
        self.minute_start = time.time()
        self._lock = asyncio.Lock()
        
        # Sistema de calibração adaptativa
        self.calibration_enabled = calibration_enabled
        self.usage_history = deque(maxlen=1000)  # Últimas 1000 requisições para calibração
        self.calibration_factor = 1.0  # Fator de correção inicial
        self.min_factor = 0.3  # Limite mínimo (30% da estimativa original)
        self.max_factor = 3.0  # Limite máximo (300% da estimativa original)
        
        # Métricas de calibração
        self.total_calibrations = 0
        self.accurate_estimates = 0  # Dentro de 20% de precisão
        self.last_recalibration = time.time()
        self.recalibration_interval = 300  # Recalibrar a cada 5 minutos
        self.total_waits = 0
        self.total_wait_time = 0.0
        
        # ✅ NOVO: Controle global de rate limit coordenado
        self._global_rate_limit_active = False
        self._global_wait_until = 0.0
        self._rate_limit_lock = asyncio.Lock()
        self._rate_limit_logged = False  # Flag para log único por batch
        self._current_batch_id = None  # Track do batch atual
        
        # Estatísticas de eficiência
        self.prevented_rate_limits = 0
        self.api_rate_limits_detected = 0  # Novos: rate limits detectados da API
        
        logger.info(
            "AdaptiveRateLimiter inicializado",
            extra={
                'max_tpm': max_tokens_per_minute,
                'calibration_enabled': calibration_enabled,
                'calibration_factor': self.calibration_factor,
                'action': 'rate_limiter_init'
            }
        )
    
    def start_batch(self, batch_id: str) -> None:
        """Inicia um novo batch - reset do controle global"""
        self._current_batch_id = batch_id
        self._rate_limit_logged = False
        self.api_rate_limits_detected = 0
        
        logger.debug(
            f"Rate limiter preparado para batch {batch_id}",
            extra={
                'batch_id': batch_id,
                'action': 'batch_rate_limit_start'
            }
        )
    
    def record_token_usage(self, estimated_tokens: int, actual_tokens: int) -> None:
        """
        Registra uso real vs estimado para calibração contínua das estimativas
        """
        if not self.calibration_enabled or actual_tokens <= 0 or estimated_tokens <= 0:
            return
        
        accuracy_ratio = actual_tokens / estimated_tokens
        
        # Criar registro para calibração
        usage_record = TokenUsageRecord(
            estimated_tokens=estimated_tokens,
            actual_tokens=actual_tokens,
            timestamp=time.time(),
            accuracy_ratio=accuracy_ratio
        )
        
        # Adicionar ao histórico para calibração
        self.usage_history.append(usage_record)
        
        # Atualizar métricas de calibração
        self.total_calibrations += 1
        if 0.8 <= accuracy_ratio <= 1.2:  # Considerar "preciso" se dentro de 20%
            self.accurate_estimates += 1
        
        # Log ocasional de progresso da calibração
        if self.total_calibrations % 100 == 0:
            accuracy_percentage = (self.accurate_estimates / self.total_calibrations) * 100
            logger.debug(
                "Progresso da calibração adaptativa",
                extra={
                    'total_calibrations': self.total_calibrations,
                    'accuracy_percentage': round(accuracy_percentage, 1),
                    'current_factor': round(self.calibration_factor, 3),
                    'action': 'calibration_progress'
                }
            )
        
        # Recalibrar periodicamente
        if time.time() - self.last_recalibration > self.recalibration_interval:
            self._recalibrate_factor()
    
    def _recalibrate_factor(self) -> None:
        """
        Recalibra o fator de correção baseado no histórico recente
        
        Usa estatística simples: média ponderada das razões de precisão
        """
        if len(self.usage_history) < 20:
            return
        
        # Usar últimas 200 requisições para recalibração (ou todas se menor)
        recent_count = min(200, len(self.usage_history))
        recent_history = list(self.usage_history)[-recent_count:]
        
        # Calcular média ponderada das razões de precisão
        # Dar mais peso para requisições mais recentes
        total_weight = 0
        weighted_sum = 0
        
        for i, record in enumerate(recent_history):
            # Peso aumenta linearmente para requisições mais recentes
            weight = (i + 1) / len(recent_history)
            weighted_sum += record.accuracy_ratio * weight
            total_weight += weight
        
        avg_accuracy = weighted_sum / total_weight if total_weight > 0 else 1.0
        
        # Suavizar mudanças (usar 60% do novo valor + 40% do antigo)
        new_factor = (avg_accuracy * 0.6) + (self.calibration_factor * 0.4)
        
        # Aplicar limites de segurança
        new_factor = max(self.min_factor, min(self.max_factor, new_factor))
        
        # Log da recalibração se mudança significativa
        if abs(new_factor - self.calibration_factor) > 0.05:
            accuracy_percentage = (self.accurate_estimates / self.total_calibrations) * 100
            
            logger.info(
                "Recalibrando fator de correção",
                extra={
                    'old_factor': round(self.calibration_factor, 3),
                    'new_factor': round(new_factor, 3),
                    'samples_used': recent_count,
                    'avg_ratio': round(avg_accuracy, 3),
                    'overall_accuracy': round(accuracy_percentage, 1),
                    'action': 'factor_recalibration'
                }
            )
        
        self.calibration_factor = new_factor
        self.last_recalibration = time.time()
    
    def get_calibrated_estimate(self, base_estimate: int) -> int:
        """
        Aplica fator de calibração à estimativa base do tiktoken
        
        Args:
            base_estimate: Estimativa base do tiktoken
            
        Returns:
            Estimativa calibrada baseada no histórico
        """
        if not self.calibration_enabled:
            return base_estimate
        
        calibrated_estimate = int(base_estimate * self.calibration_factor)
        
        return calibrated_estimate
    
    async def wait_for_tokens(self, estimated_tokens: int) -> int:
        """
        Aguarda tokens disponíveis com controle global coordenado
        
        Args:
            estimated_tokens: Estimativa base (geralmente do tiktoken)
            
        Returns:
            Estimativa calibrada usada para rate limiting
        """
        # ✅ VERIFICAR se há rate limit global ativo primeiro
        async with self._rate_limit_lock:
            current_time = time.time()
            
            # Se há rate limit global ativo
            if self._global_rate_limit_active and current_time < self._global_wait_until:
                remaining_wait = self._global_wait_until - current_time
                
                # ✅ LOG ÚNICO por batch
                if not self._rate_limit_logged:
                    logger.warning(
                        f"Rate limit global ativo - todas as requests aguardarão {remaining_wait:.1f}s",
                        extra={
                            'batch_id': self._current_batch_id,
                            'global_wait_time': round(remaining_wait, 1),
                            'wait_until_timestamp': self._global_wait_until,
                            'api_rate_limits_detected': self.api_rate_limits_detected,
                            'action': 'global_rate_limit_wait'
                        }
                    )
                    self._rate_limit_logged = True
                
                # Aguardar fora do lock
                await asyncio.sleep(remaining_wait)
                
                # Reset do rate limit global
                self._global_rate_limit_active = False
                
                logger.debug(
                    "Rate limit global finalizado",
                    extra={
                        'batch_id': self._current_batch_id,
                        'action': 'global_rate_limit_end'
                    }
                )
        
        # Aplicar calibração baseada no histórico
        calibrated_tokens = self.get_calibrated_estimate(estimated_tokens)
        
        # Rate limiting normal (proativo)
        async with self._lock:
            current_time = time.time()
            
            # Reset contador a cada minuto
            if current_time - self.minute_start >= 60:
                if self.tokens_used_this_minute > 0:
                    utilization = (self.tokens_used_this_minute / self.max_tpm) * 100
                    logger.debug(
                        "Reset de minuto - utilização",
                        extra={
                            'tokens_used': self.tokens_used_this_minute,
                            'utilization_percent': round(utilization, 1),
                            'action': 'minute_reset'
                        }
                    )
                
                self.tokens_used_this_minute = 0
                self.minute_start = current_time
            
            # Verificar se precisa aguardar (rate limiting proativo)
            if self.tokens_used_this_minute + calibrated_tokens > self.max_tpm:
                wait_time = 60 - (current_time - self.minute_start)
                
                if wait_time > 0:
                    # ✅ ATIVAR rate limit global coordenado
                    await self._activate_global_rate_limit(wait_time, 'proactive')
                    
                    # Reset após espera
                    self.tokens_used_this_minute = 0
                    self.minute_start = time.time()
        
        return calibrated_tokens
    
    async def _activate_global_rate_limit(self, wait_time: float, source: str = 'api'):
        """Ativa rate limit global para todas as requests"""
        async with self._rate_limit_lock:
            current_time = time.time()
            new_wait_until = current_time + wait_time
            
            # Só atualizar se é maior que o atual (evitar conflitos)
            if new_wait_until > self._global_wait_until:
                self._global_rate_limit_active = True
                self._global_wait_until = new_wait_until
                self._rate_limit_logged = False  # Reset para permitir novo log
                
                self.total_waits += 1
                self.total_wait_time += wait_time
                self.prevented_rate_limits += 1
                
                logger.debug(
                    f"Rate limit global ativado - fonte: {source}",
                    extra={
                        'batch_id': self._current_batch_id,
                        'wait_time': round(wait_time, 1),
                        'source': source,
                        'action': 'global_rate_limit_activated'
                    }
                )
    
    def record_api_rate_limit(self, wait_time: float):
        """
        Registra rate limit detectado pela API (Azure/OpenAI)
        
        Args:
            wait_time: Tempo de espera solicitado pela API
        """
        self.api_rate_limits_detected += 1
        
        # Ativar rate limit global de forma assíncrona
        async def _set_global_limit():
            await self._activate_global_rate_limit(wait_time, 'api')
        
        # Criar task para não bloquear
        asyncio.create_task(_set_global_limit())
        
        logger.debug(
            f"Rate limit da API detectado - #{self.api_rate_limits_detected}",
            extra={
                'batch_id': self._current_batch_id,
                'wait_time': round(wait_time, 1),
                'total_api_rate_limits': self.api_rate_limits_detected,
                'action': 'api_rate_limit_detected'
            }
        )
    
    def record_tokens(self, tokens_used: int) -> None:
        """
        Registra tokens utilizados no contador atual
        """
        self.tokens_used_this_minute += tokens_used
        
        # Log de alta utilização
        if self.tokens_used_this_minute > self.max_tpm * 0.9:
            logger.warning(
                "Alta utilização de tokens detectada",
                extra={
                    'tokens_used': self.tokens_used_this_minute,
                    'tokens_limit': self.max_tpm,
                    'utilization_percent': round((self.tokens_used_this_minute / self.max_tpm) * 100, 1),
                    'action': 'high_utilization'
                }
            )
    
    def get_status(self) -> Dict[str, Any]:
        """
        Retorna status atual do rate limiter
        """
        current_time = time.time()
        time_in_minute = current_time - self.minute_start
        tokens_remaining = max(0, self.max_tpm - self.tokens_used_this_minute)
        utilization = (self.tokens_used_this_minute / self.max_tpm) * 100
        
        # Calcular precisão da calibração
        accuracy_percentage = (self.accurate_estimates / self.total_calibrations * 100) if self.total_calibrations > 0 else 0
        
        return {
            'tokens_used': self.tokens_used_this_minute,
            'tokens_limit': self.max_tpm,
            'tokens_remaining': tokens_remaining,
            'utilization_percent': round(utilization, 2),
            'time_in_minute': round(time_in_minute, 2),
            'total_waits': self.total_waits,
            'total_wait_time': round(self.total_wait_time, 2),
            'calibration_factor': round(self.calibration_factor, 3),
            'calibration_accuracy': round(accuracy_percentage, 1),
            'total_calibrations': self.total_calibrations,
            'prevented_rate_limits': self.prevented_rate_limits,
            'api_rate_limits_detected': self.api_rate_limits_detected,
            'global_rate_limit_active': self._global_rate_limit_active,
            'current_batch_id': self._current_batch_id
        }
    
    def get_calibration_stats(self) -> Dict[str, Any]:
        """
        Retorna estatísticas detalhadas de calibração
        """
        accuracy_percentage = (self.accurate_estimates / self.total_calibrations * 100) if self.total_calibrations > 0 else 0
        
        return {
            'calibration_enabled': self.calibration_enabled,
            'total_calibrations': self.total_calibrations,
            'accurate_estimates': self.accurate_estimates,
            'accuracy_percentage': round(accuracy_percentage, 2),
            'current_calibration_factor': round(self.calibration_factor, 3),
            'history_size': len(self.usage_history),
            'last_recalibration': self.last_recalibration,
            'prevented_rate_limits': self.prevented_rate_limits,
            'api_rate_limits_detected': self.api_rate_limits_detected,
            'efficiency_metrics': {
                'avg_wait_time': round(self.total_wait_time / self.total_waits, 2) if self.total_waits > 0 else 0,
                'wait_frequency': round(self.total_waits / self.total_calibrations, 3) if self.total_calibrations > 0 else 0
            },
            'global_coordination': {
                'global_rate_limit_active': self._global_rate_limit_active,
                'current_batch_id': self._current_batch_id,
                'rate_limit_logged': self._rate_limit_logged
            }
        }
    
    def reset_calibration(self) -> None:
        """
        Reseta o sistema de calibração (manter configurações básicas)
        """
        logger.info("Resetando sistema de calibração do RateLimiter")
        
        self.usage_history.clear()
        self.calibration_factor = 1.0
        self.total_calibrations = 0
        self.accurate_estimates = 0
        self.last_recalibration = time.time()
        self.prevented_rate_limits = 0
        self.api_rate_limits_detected = 0
        
        # Reset controle global
        self._global_rate_limit_active = False
        self._global_wait_until = 0.0
        self._rate_limit_logged = False
    
    def disable_calibration(self) -> None:
        """
        Desabilita o sistema de calibração (usar apenas estimativas base)
        """
        logger.info("Desabilitando sistema de calibração do RateLimiter")
        self.calibration_enabled = False
        self.calibration_factor = 1.0
    
    def enable_calibration(self) -> None:
        """
        Habilita o sistema de calibração
        """
        logger.info("Habilitando sistema de calibração do RateLimiter")
        self.calibration_enabled = True
    
    def log_performance_summary(self) -> None:
        """
        Log de resumo de performance para análise
        """
        if self.total_calibrations > 0:
            avg_wait_time = self.total_wait_time / self.total_waits if self.total_waits > 0 else 0
            accuracy_percentage = (self.accurate_estimates / self.total_calibrations) * 100
            
            logger.info(
                "Resumo de performance do RateLimiter",
                extra={
                    'total_calibrations': self.total_calibrations,
                    'calibration_accuracy': round(accuracy_percentage, 2),
                    'calibration_factor': round(self.calibration_factor, 3),
                    'total_waits': self.total_waits,
                    'total_wait_time': round(self.total_wait_time, 2),
                    'average_wait_time': round(avg_wait_time, 2),
                    'prevented_rate_limits': self.prevented_rate_limits,
                    'api_rate_limits_detected': self.api_rate_limits_detected,
                    'max_tpm': self.max_tpm,
                    'efficiency_percent': round(100 - (self.total_wait_time / 60 * 100), 2) if self.total_wait_time < 60 else 0,
                    'action': 'performance_summary'
                }
            )
    
    def __del__(self):
        """
        Log final quando objeto é destruído
        """
        try:
            self.log_performance_summary()
        except:
            pass  # Evitar erros durante destruição
