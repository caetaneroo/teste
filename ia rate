# core/rate_limiter.py
import asyncio
import time
import logging
from typing import Dict, Any, Optional
from collections import deque
from dataclasses import dataclass

# Logger espec√≠fico do m√≥dulo
logger = logging.getLogger(__name__)

@dataclass
class TokenUsageRecord:
    """Registro de uso de tokens para calibra√ß√£o adaptativa"""
    estimated_tokens: int
    actual_tokens: int
    timestamp: float
    accuracy_ratio: float

class AdaptiveRateLimiter:
    """
    Rate limiter com calibra√ß√£o adaptativa e logs organizados por responsabilidade
    
    Caracter√≠sticas:
    - Calibra estimativas com base em dados hist√≥ricos reais
    - Auto-ajuste estat√≠stico para otimizar precis√£o
    - Rate limiting global coordenado com logs centralizados
    - Preven√ß√£o proativa de rate limits
    - M√°ximo aproveitamento da quota dispon√≠vel
    - Logs organizados por eventos (n√£o por requests individuais)
    - SEM redu√ß√£o autom√°tica de capacidade
    """
    
    def __init__(self, max_tokens_per_minute: int = 180000, calibration_enabled: bool = True):
        self.max_tpm = max_tokens_per_minute
        self.tokens_used_this_minute = 0
        self.minute_start = time.time()
        self._lock = asyncio.Lock()
        
        # Sistema de calibra√ß√£o adaptativa
        self.calibration_enabled = calibration_enabled
        self.usage_history = deque(maxlen=1000)  # √öltimas 1000 requisi√ß√µes para calibra√ß√£o
        self.calibration_factor = 1.0  # Fator de corre√ß√£o inicial
        self.min_factor = 0.3  # Limite m√≠nimo (30% da estimativa original)
        self.max_factor = 3.0  # Limite m√°ximo (300% da estimativa original)
        
        # M√©tricas de calibra√ß√£o
        self.total_calibrations = 0
        self.accurate_estimates = 0  # Dentro de 20% de precis√£o
        self.last_recalibration = time.time()
        self.recalibration_interval = 300  # Recalibrar a cada 5 minutos
        self.total_waits = 0
        self.total_wait_time = 0.0
        
        # ‚úÖ CONTROLE GLOBAL DE RATE LIMIT COORDENADO
        self._global_rate_limit_active = False
        self._global_wait_until = 0.0
        self._rate_limit_lock = asyncio.Lock()
        self._rate_limit_logged = False  # Flag para log √∫nico por batch
        self._current_batch_id = None  # Track do batch atual
        
        # ‚úÖ CONTROLE DE EVENTOS DE RATE LIMIT (logs organizados)
        self._rate_limit_events = 0
        self._rate_limit_event_active = False
        
        # Estat√≠sticas de efici√™ncia
        self.prevented_rate_limits = 0
        self.api_rate_limits_detected = 0  # Rate limits detectados da API
        
        logger.info(
            "AdaptiveRateLimiter inicializado",
            extra={
                'max_tpm': max_tokens_per_minute,
                'calibration_enabled': calibration_enabled,
                'calibration_factor': self.calibration_factor,
                'action': 'rate_limiter_init'
            }
        )
    
    def start_batch(self, batch_id: str) -> None:
        """Inicia um novo batch - reset completo de controles"""
        self._current_batch_id = batch_id
        self._rate_limit_logged = False
        self._rate_limit_events = 0
        self._rate_limit_event_active = False
        self.api_rate_limits_detected = 0
        
        logger.debug(
            f"Rate limiter preparado para batch {batch_id}",
            extra={
                'batch_id': batch_id,
                'action': 'batch_rate_limit_start'
            }
        )
    
    def record_token_usage(self, estimated_tokens: int, actual_tokens: int) -> None:
        """
        Registra uso real vs estimado para calibra√ß√£o cont√≠nua das estimativas
        """
        if not self.calibration_enabled or actual_tokens <= 0 or estimated_tokens <= 0:
            return
        
        accuracy_ratio = actual_tokens / estimated_tokens
        
        # Criar registro para calibra√ß√£o
        usage_record = TokenUsageRecord(
            estimated_tokens=estimated_tokens,
            actual_tokens=actual_tokens,
            timestamp=time.time(),
            accuracy_ratio=accuracy_ratio
        )
        
        # Adicionar ao hist√≥rico para calibra√ß√£o
        self.usage_history.append(usage_record)
        
        # Atualizar m√©tricas de calibra√ß√£o
        self.total_calibrations += 1
        if 0.8 <= accuracy_ratio <= 1.2:  # Considerar "preciso" se dentro de 20%
            self.accurate_estimates += 1
        
        # Log ocasional de progresso da calibra√ß√£o
        if self.total_calibrations % 100 == 0:
            accuracy_percentage = (self.accurate_estimates / self.total_calibrations) * 100
            logger.debug(
                "Progresso da calibra√ß√£o adaptativa",
                extra={
                    'total_calibrations': self.total_calibrations,
                    'accuracy_percentage': round(accuracy_percentage, 1),
                    'current_factor': round(self.calibration_factor, 3),
                    'action': 'calibration_progress'
                }
            )
        
        # Recalibrar periodicamente
        if time.time() - self.last_recalibration > self.recalibration_interval:
            self._recalibrate_factor()
    
    def _recalibrate_factor(self) -> None:
        """
        Recalibra o fator de corre√ß√£o baseado no hist√≥rico recente
        """
        if len(self.usage_history) < 20:
            return
        
        # Usar √∫ltimas 200 requisi√ß√µes para recalibra√ß√£o (ou todas se menor)
        recent_count = min(200, len(self.usage_history))
        recent_history = list(self.usage_history)[-recent_count:]
        
        # Calcular m√©dia ponderada das raz√µes de precis√£o
        total_weight = 0
        weighted_sum = 0
        
        for i, record in enumerate(recent_history):
            # Peso aumenta linearmente para requisi√ß√µes mais recentes
            weight = (i + 1) / len(recent_history)
            weighted_sum += record.accuracy_ratio * weight
            total_weight += weight
        
        avg_accuracy = weighted_sum / total_weight if total_weight > 0 else 1.0
        
        # Suavizar mudan√ßas (usar 60% do novo valor + 40% do antigo)
        new_factor = (avg_accuracy * 0.6) + (self.calibration_factor * 0.4)
        
        # Aplicar limites de seguran√ßa
        new_factor = max(self.min_factor, min(self.max_factor, new_factor))
        
        # Log da recalibra√ß√£o se mudan√ßa significativa
        if abs(new_factor - self.calibration_factor) > 0.05:
            accuracy_percentage = (self.accurate_estimates / self.total_calibrations) * 100
            
            logger.info(
                "Recalibrando fator de corre√ß√£o",
                extra={
                    'old_factor': round(self.calibration_factor, 3),
                    'new_factor': round(new_factor, 3),
                    'samples_used': recent_count,
                    'avg_ratio': round(avg_accuracy, 3),
                    'overall_accuracy': round(accuracy_percentage, 1),
                    'action': 'factor_recalibration'
                }
            )
        
        self.calibration_factor = new_factor
        self.last_recalibration = time.time()
    
    def get_calibrated_estimate(self, base_estimate: int) -> int:
        """
        Aplica fator de calibra√ß√£o √† estimativa base do tiktoken
        """
        if not self.calibration_enabled:
            return base_estimate
        
        calibrated_estimate = int(base_estimate * self.calibration_factor)
        return calibrated_estimate
    
    async def wait_for_tokens(self, estimated_tokens: int) -> int:
        """
        Aguarda tokens dispon√≠veis com controle global coordenado
        """
        # ‚úÖ VERIFICAR se h√° rate limit global ativo primeiro
        async with self._rate_limit_lock:
            current_time = time.time()
            
            # Se h√° rate limit global ativo
            if self._global_rate_limit_active and current_time < self._global_wait_until:
                remaining_wait = self._global_wait_until - current_time
                
                # ‚úÖ LOG √öNICO por batch
                if not self._rate_limit_logged:
                    logger.warning(
                        f"‚è≥ Iniciando pausa global de {remaining_wait:.1f}s para rate limit",
                        extra={
                            'batch_id': self._current_batch_id,
                            'global_wait_time': round(remaining_wait, 1),
                            'wait_until_timestamp': self._global_wait_until,
                            'api_rate_limits_detected': self.api_rate_limits_detected,
                            'action': 'global_rate_limit_pause_start'
                        }
                    )
                    self._rate_limit_logged = True
                
                # Aguardar fora do lock
                await asyncio.sleep(remaining_wait)
                
                # Reset do rate limit global
                self._global_rate_limit_active = False
                
                logger.info(
                    "‚úÖ Pausa de rate limit finalizada - processamento retomado",
                    extra={
                        'batch_id': self._current_batch_id,
                        'action': 'rate_limit_pause_end'
                    }
                )
        
        # Aplicar calibra√ß√£o baseada no hist√≥rico
        calibrated_tokens = self.get_calibrated_estimate(estimated_tokens)
        
        # Rate limiting normal (proativo) - SEM redu√ß√£o de capacidade
        async with self._lock:
            current_time = time.time()
            
            # Reset contador a cada minuto
            if current_time - self.minute_start >= 60:
                if self.tokens_used_this_minute > 0:
                    utilization = (self.tokens_used_this_minute / self.max_tpm) * 100
                    logger.debug(
                        "Reset de minuto - utiliza√ß√£o",
                        extra={
                            'tokens_used': self.tokens_used_this_minute,
                            'max_tpm': self.max_tpm,
                            'utilization_percent': round(utilization, 1),
                            'action': 'minute_reset'
                        }
                    )
                
                self.tokens_used_this_minute = 0
                self.minute_start = current_time
            
            # ‚úÖ USAR capacidade m√°xima sempre (sem redu√ß√£o)
            if self.tokens_used_this_minute + calibrated_tokens > self.max_tpm:
                wait_time = 60 - (current_time - self.minute_start)
                
                if wait_time > 0:
                    # Rate limiting proativo SEM log global - apenas aguardar localmente
                    logger.debug(
                        f"Rate limiting proativo - aguardando {wait_time:.1f}s",
                        extra={
                            'wait_time': wait_time,
                            'max_tpm': self.max_tpm,
                            'action': 'proactive_rate_limit'
                        }
                    )
                    await asyncio.sleep(wait_time)
                    self.tokens_used_this_minute = 0
                    self.minute_start = time.time()
        
        return calibrated_tokens
    
    async def _activate_global_rate_limit(self, wait_time: float, source: str = 'api'):
        """Ativa rate limit global para todas as requests"""
        async with self._rate_limit_lock:
            current_time = time.time()
            new_wait_until = current_time + wait_time
            
            # S√≥ atualizar se √© maior que o atual (evitar conflitos)
            if new_wait_until > self._global_wait_until:
                self._global_rate_limit_active = True
                self._global_wait_until = new_wait_until
                self._rate_limit_logged = False  # Reset para permitir novo log
                
                self.total_waits += 1
                self.total_wait_time += wait_time
                self.prevented_rate_limits += 1
                
                logger.debug(
                    f"Rate limit global ativado - fonte: {source}",
                    extra={
                        'batch_id': self._current_batch_id,
                        'wait_time': round(wait_time, 1),
                        'source': source,
                        'action': 'global_rate_limit_activated'
                    }
                )
    
    def record_api_rate_limit_with_context(self, wait_time: float, completed: int, total: int, successful: int, failed: int):
        """
        ‚úÖ LOGS ORGANIZADOS: Registra rate limit da API com contexto completo e logs apropriados
        """
        
        # Verificar se √© um novo evento de rate limit
        if not self._rate_limit_event_active:
            self._rate_limit_event_active = True
            self._rate_limit_events += 1
            
            remaining = total - completed
            
            # ‚úÖ LOG DE INFO: Status quando atingiu rate limit
            logger.info(
                f"üìä Status no rate limit: {completed}/{total} processados | "
                f"‚úÖ{successful} ‚ùå{failed} | "
                f"üîÑ{remaining} restantes",
                extra={
                    'batch_id': self._current_batch_id,
                    'completed': completed,
                    'total': total,
                    'successful_so_far': successful,
                    'failed_so_far': failed,
                    'remaining': remaining,
                    'action': 'rate_limit_status_info'
                }
            )
            
            # ‚úÖ LOG DE WARNING: Evento de rate limit
            logger.warning(
                f"üö® Rate limit evento #{self._rate_limit_events} detectado! "
                f"Aguardando coordena√ß√£o global...",
                extra={
                    'batch_id': self._current_batch_id,
                    'rate_limit_event_number': self._rate_limit_events,
                    'completed_at_rate_limit': completed,
                    'wait_time': wait_time,
                    'action': 'rate_limit_event_warning'
                }
            )
        
        # Ativar rate limit global
        self.api_rate_limits_detected += 1
        async def _set_global_limit():
            await self._activate_global_rate_limit(wait_time, 'api_detected')
        
        asyncio.create_task(_set_global_limit())
    
    def record_successful_request(self):
        """
        ‚úÖ LOGS ORGANIZADOS: Registra request bem-sucedida - pode resetar evento de rate limit
        """
        if self._rate_limit_event_active:
            self._rate_limit_event_active = False
            logger.info(
                "‚úÖ Rate limit resolvido - processamento normal retomado",
                extra={
                    'batch_id': self._current_batch_id,
                    'action': 'rate_limit_resolved'
                }
            )
    
    def record_tokens(self, tokens_used: int) -> None:
        """
        Registra tokens utilizados no contador atual
        """
        self.tokens_used_this_minute += tokens_used
        
        # Log de alta utiliza√ß√£o (usando capacidade m√°xima sempre)
        if self.tokens_used_this_minute > self.max_tpm * 0.9:
            logger.warning(
                "Alta utiliza√ß√£o de tokens detectada",
                extra={
                    'tokens_used': self.tokens_used_this_minute,
                    'max_tpm': self.max_tpm,
                    'utilization_percent': round((self.tokens_used_this_minute / self.max_tpm) * 100, 1),
                    'action': 'high_utilization'
                }
            )
    
    def get_status(self) -> Dict[str, Any]:
        """
        Retorna status atual do rate limiter
        """
        current_time = time.time()
        time_in_minute = current_time - self.minute_start
        tokens_remaining = max(0, self.max_tpm - self.tokens_used_this_minute)
        utilization = (self.tokens_used_this_minute / self.max_tpm) * 100
        
        # Calcular precis√£o da calibra√ß√£o
        accuracy_percentage = (self.accurate_estimates / self.total_calibrations * 100) if self.total_calibrations > 0 else 0
        
        return {
            'tokens_used': self.tokens_used_this_minute,
            'tokens_limit': self.max_tpm,
            'tokens_remaining': tokens_remaining,
            'utilization_percent': round(utilization, 2),
            'time_in_minute': round(time_in_minute, 2),
            'total_waits': self.total_waits,
            'total_wait_time': round(self.total_wait_time, 2),
            'calibration_factor': round(self.calibration_factor, 3),
            'calibration_accuracy': round(accuracy_percentage, 1),
            'total_calibrations': self.total_calibrations,
            'prevented_rate_limits': self.prevented_rate_limits,
            'api_rate_limits_detected': self.api_rate_limits_detected,
            'rate_limit_events': self._rate_limit_events,
            'global_rate_limit_active': self._global_rate_limit_active,
            'current_batch_id': self._current_batch_id
        }
    
    def get_calibration_stats(self) -> Dict[str, Any]:
        """
        Retorna estat√≠sticas detalhadas de calibra√ß√£o
        """
        accuracy_percentage = (self.accurate_estimates / self.total_calibrations * 100) if self.total_calibrations > 0 else 0
        
        return {
            'calibration_enabled': self.calibration_enabled,
            'total_calibrations': self.total_calibrations,
            'accurate_estimates': self.accurate_estimates,
            'accuracy_percentage': round(accuracy_percentage, 2),
            'current_calibration_factor': round(self.calibration_factor, 3),
            'history_size': len(self.usage_history),
            'last_recalibration': self.last_recalibration,
            'prevented_rate_limits': self.prevented_rate_limits,
            'api_rate_limits_detected': self.api_rate_limits_detected,
            'rate_limit_events': self._rate_limit_events,
            'efficiency_metrics': {
                'avg_wait_time': round(self.total_wait_time / self.total_waits, 2) if self.total_waits > 0 else 0,
                'wait_frequency': round(self.total_waits / self.total_calibrations, 3) if self.total_calibrations > 0 else 0
            },
            'global_coordination': {
                'global_rate_limit_active': self._global_rate_limit_active,
                'current_batch_id': self._current_batch_id,
                'rate_limit_logged': self._rate_limit_logged
            }
        }
    
    def reset_calibration(self) -> None:
        """
        Reseta o sistema de calibra√ß√£o (manter configura√ß√µes b√°sicas)
        """
        logger.info("Resetando sistema de calibra√ß√£o do RateLimiter")
        
        self.usage_history.clear()
        self.calibration_factor = 1.0
        self.total_calibrations = 0
        self.accurate_estimates = 0
        self.last_recalibration = time.time()
        self.prevented_rate_limits = 0
        self.api_rate_limits_detected = 0
        self._rate_limit_events = 0
        
        # Reset controle global
        self._global_rate_limit_active = False
        self._global_wait_until = 0.0
        self._rate_limit_logged = False
        self._rate_limit_event_active = False
    
    def disable_calibration(self) -> None:
        """
        Desabilita o sistema de calibra√ß√£o (usar apenas estimativas base)
        """
        logger.info("Desabilitando sistema de calibra√ß√£o do RateLimiter")
        self.calibration_enabled = False
        self.calibration_factor = 1.0
    
    def enable_calibration(self) -> None:
        """
        Habilita o sistema de calibra√ß√£o
        """
        logger.info("Habilitando sistema de calibra√ß√£o do RateLimiter")
        self.calibration_enabled = True
    
    def log_performance_summary(self) -> None:
        """
        Log de resumo de performance para an√°lise
        """
        if self.total_calibrations > 0:
            avg_wait_time = self.total_wait_time / self.total_waits if self.total_waits > 0 else 0
            accuracy_percentage = (self.accurate_estimates / self.total_calibrations) * 100
            
            logger.info(
                "Resumo de performance do RateLimiter",
                extra={
                    'total_calibrations': self.total_calibrations,
                    'calibration_accuracy': round(accuracy_percentage, 2),
                    'calibration_factor': round(self.calibration_factor, 3),
                    'total_waits': self.total_waits,
                    'total_wait_time': round(self.total_wait_time, 2),
                    'average_wait_time': round(avg_wait_time, 2),
                    'prevented_rate_limits': self.prevented_rate_limits,
                    'api_rate_limits_detected': self.api_rate_limits_detected,
                    'rate_limit_events': self._rate_limit_events,
                    'max_tpm': self.max_tpm,
                    'efficiency_percent': round(100 - (self.total_wait_time / 60 * 100), 2) if self.total_wait_time < 60 else 0,
                    'action': 'performance_summary'
                }
            )
    
    def __del__(self):
        """
        Log final quando objeto √© destru√≠do
        """
        try:
            self.log_performance_summary()
        except:
            pass  # Evitar erros durante destrui√ß√£o
